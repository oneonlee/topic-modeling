{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7a3b1fe",
   "metadata": {},
   "source": [
    "## 필요한 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a1cad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-08 17:38:03.580541: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-08 17:38:03.580568: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-10-08 17:38:04.469720: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-10-08 17:38:04.469748: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-10-08 17:38:04.469764: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-inha): /proc/driver/nvidia/version does not exist\n",
      "2021-10-08 17:38:04.469957: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from pykospacing import Spacing\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from hanspell import spell_checker\n",
    "import re\n",
    "\n",
    "spacing = Spacing()\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d176c12e",
   "metadata": {},
   "source": [
    "## data.csv 파일 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60fffb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pre-data/data.csv',encoding='cp949',\n",
    "                 low_memory=False)\n",
    "df = df[['title', '개월']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db445d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>개월</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>조리원에서 유축한것도 직접 먹이시나요!?</td>\n",
       "      <td>0개월</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>혼합수유에서 분유수유만 하려면 어떻게 해야하나요?</td>\n",
       "      <td>0개월</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>신생아 밥 달라고할때마다 줘도되나요?도와주세요</td>\n",
       "      <td>0개월</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>수술 3일차인데, 모유수유 내일부터 시작해도 될까요?</td>\n",
       "      <td>0개월</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>조리원퇴소.. 유축기 사야하나요?</td>\n",
       "      <td>0개월</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13790</th>\n",
       "      <td>냉동실에 있던 모유 냉장실에~</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13791</th>\n",
       "      <td>아기가 많이 못빨았을때 유축하는게 맞나요?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13792</th>\n",
       "      <td>가슴이 땅땅하고 너무 아픈데 어떻게 해야할까요??</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13793</th>\n",
       "      <td>남양 ㅇㅏ이엠마더 먹이는분계시나용 ㅠㅠ?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13794</th>\n",
       "      <td>하...아기가 잘 안자고 금방 다음 수유시간 와버리네요ㅋㅋㅋ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13795 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title   개월\n",
       "0                 조리원에서 유축한것도 직접 먹이시나요!?  0개월\n",
       "1            혼합수유에서 분유수유만 하려면 어떻게 해야하나요?  0개월\n",
       "2              신생아 밥 달라고할때마다 줘도되나요?도와주세요  0개월\n",
       "3          수술 3일차인데, 모유수유 내일부터 시작해도 될까요?  0개월\n",
       "4                     조리원퇴소.. 유축기 사야하나요?  0개월\n",
       "...                                  ...  ...\n",
       "13790                   냉동실에 있던 모유 냉장실에~  NaN\n",
       "13791            아기가 많이 못빨았을때 유축하는게 맞나요?  NaN\n",
       "13792        가슴이 땅땅하고 너무 아픈데 어떻게 해야할까요??  NaN\n",
       "13793             남양 ㅇㅏ이엠마더 먹이는분계시나용 ㅠㅠ?  NaN\n",
       "13794  하...아기가 잘 안자고 금방 다음 수유시간 와버리네요ㅋㅋㅋ  NaN\n",
       "\n",
       "[13795 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b6d154",
   "metadata": {},
   "source": [
    "## 불용어(stopwords) 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98656b2a",
   "metadata": {},
   "source": [
    "### 불용어 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc80c339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nursing</th>\n",
       "      <th>korean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>가</td>\n",
       "      <td>아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>가라</td>\n",
       "      <td>휴</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>가지</td>\n",
       "      <td>아이구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>각</td>\n",
       "      <td>아이쿠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>간</td>\n",
       "      <td>아이고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>흑</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>흑흑</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>흔히</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>흠뻑</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>힝</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1436 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     nursing korean\n",
       "0          가      아\n",
       "1         가라      휴\n",
       "2         가지    아이구\n",
       "3          각    아이쿠\n",
       "4          간    아이고\n",
       "...      ...    ...\n",
       "1431       흑    NaN\n",
       "1432      흑흑    NaN\n",
       "1433      흔히    NaN\n",
       "1434      흠뻑    NaN\n",
       "1435       힝    NaN\n",
       "\n",
       "[1436 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_df=pd.read_csv('pre-data/stopwords.csv', encoding='utf-8',\n",
    "                 low_memory=False)\n",
    "stopwords_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff583964",
   "metadata": {},
   "source": [
    "### 불용어 제거 (nuring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "312ada06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 13795\n",
      "1 of 13795\n",
      "2 of 13795\n",
      "3 of 13795\n",
      "4 of 13795\n",
      "5 of 13795\n",
      "6 of 13795\n",
      "7 of 13795\n",
      "8 of 13795\n",
      "9 of 13795\n",
      "10 of 13795\n",
      "11 of 13795\n",
      "12 of 13795\n",
      "13 of 13795\n",
      "14 of 13795\n",
      "15 of 13795\n",
      "16 of 13795\n",
      "17 of 13795\n",
      "18 of 13795\n",
      "19 of 13795\n",
      "20 of 13795\n",
      "21 of 13795\n",
      "22 of 13795\n",
      "23 of 13795\n",
      "24 of 13795\n",
      "25 of 13795\n",
      "26 of 13795\n",
      "27 of 13795\n",
      "28 of 13795\n",
      "29 of 13795\n",
      "30 of 13795\n",
      "31 of 13795\n",
      "32 of 13795\n",
      "33 of 13795\n",
      "34 of 13795\n",
      "35 of 13795\n",
      "36 of 13795\n",
      "37 of 13795\n",
      "38 of 13795\n",
      "39 of 13795\n",
      "40 of 13795\n",
      "41 of 13795\n",
      "42 of 13795\n",
      "43 of 13795\n",
      "44 of 13795\n",
      "45 of 13795\n",
      "46 of 13795\n",
      "47 of 13795\n",
      "48 of 13795\n",
      "49 of 13795\n",
      "50 of 13795\n",
      "51 of 13795\n",
      "52 of 13795\n",
      "53 of 13795\n",
      "54 of 13795\n",
      "55 of 13795\n",
      "56 of 13795\n",
      "57 of 13795\n",
      "58 of 13795\n",
      "59 of 13795\n",
      "60 of 13795\n",
      "61 of 13795\n",
      "62 of 13795\n",
      "63 of 13795\n",
      "64 of 13795\n",
      "65 of 13795\n",
      "66 of 13795\n",
      "67 of 13795\n",
      "68 of 13795\n",
      "69 of 13795\n",
      "70 of 13795\n",
      "71 of 13795\n",
      "72 of 13795\n",
      "73 of 13795\n",
      "74 of 13795\n",
      "75 of 13795\n",
      "76 of 13795\n",
      "77 of 13795\n",
      "78 of 13795\n",
      "79 of 13795\n",
      "80 of 13795\n",
      "81 of 13795\n",
      "82 of 13795\n",
      "83 of 13795\n",
      "84 of 13795\n",
      "85 of 13795\n",
      "86 of 13795\n",
      "87 of 13795\n",
      "88 of 13795\n",
      "89 of 13795\n",
      "90 of 13795\n",
      "91 of 13795\n",
      "92 of 13795\n",
      "93 of 13795\n",
      "94 of 13795\n",
      "95 of 13795\n",
      "96 of 13795\n",
      "97 of 13795\n",
      "98 of 13795\n",
      "99 of 13795\n",
      "100 of 13795\n",
      "101 of 13795\n",
      "102 of 13795\n",
      "103 of 13795\n",
      "104 of 13795\n",
      "105 of 13795\n",
      "106 of 13795\n",
      "107 of 13795\n",
      "108 of 13795\n",
      "109 of 13795\n",
      "110 of 13795\n",
      "111 of 13795\n",
      "112 of 13795\n",
      "113 of 13795\n",
      "114 of 13795\n",
      "115 of 13795\n",
      "116 of 13795\n",
      "117 of 13795\n",
      "118 of 13795\n",
      "119 of 13795\n",
      "120 of 13795\n",
      "121 of 13795\n",
      "122 of 13795\n",
      "123 of 13795\n",
      "124 of 13795\n",
      "125 of 13795\n",
      "126 of 13795\n",
      "127 of 13795\n",
      "128 of 13795\n",
      "129 of 13795\n",
      "130 of 13795\n",
      "131 of 13795\n",
      "132 of 13795\n",
      "133 of 13795\n",
      "134 of 13795\n",
      "135 of 13795\n",
      "136 of 13795\n",
      "137 of 13795\n",
      "138 of 13795\n",
      "139 of 13795\n",
      "140 of 13795\n",
      "141 of 13795\n",
      "142 of 13795\n",
      "143 of 13795\n",
      "144 of 13795\n",
      "145 of 13795\n",
      "146 of 13795\n",
      "147 of 13795\n",
      "148 of 13795\n",
      "149 of 13795\n",
      "150 of 13795\n",
      "151 of 13795\n",
      "152 of 13795\n",
      "153 of 13795\n",
      "154 of 13795\n",
      "155 of 13795\n",
      "156 of 13795\n",
      "157 of 13795\n",
      "158 of 13795\n",
      "159 of 13795\n",
      "160 of 13795\n",
      "161 of 13795\n",
      "162 of 13795\n",
      "163 of 13795\n",
      "164 of 13795\n",
      "165 of 13795\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_52580/3043613002.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nursing'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstopwords_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nursing\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{i} of {len_df}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcacher_needs_updating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_with_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_maybe_update_cacher\u001b[0;34m(self, clear, verify_is_copy)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                 \u001b[0;31m# to ensure column still in dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m                 \u001b[0;31m# otherwise, either self or ref has swapped in new arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                 \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cache_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcacher\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                 \u001b[0;31m# GH#33675 we have swapped in a new array, so parent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_maybe_cache_changed\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   3903\u001b[0m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3904\u001b[0m         \u001b[0marraylike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3905\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marraylike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3907\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36miset\u001b[0;34m(self, loc, value)\u001b[0m\n\u001b[1;32m   1076\u001b[0m             \u001b[0mblk_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m                 \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1079\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0munfit_mgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mset_inplace\u001b[0;34m(self, locs, values)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mcreate\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnew\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0malways\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \"\"\"\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# nursing\n",
    "len_df = len(df)\n",
    "for i in range(len_df):\n",
    "    for j in range(len(stopwords_df['nursing'])):\n",
    "        df['title'][i] = re.sub(\" \"+stopwords_df.loc[j][\"nursing\"]+\" \", \" \", df['title'][i])\n",
    "    print(f\"{i} of {len_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2853aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea64c4d",
   "metadata": {},
   "source": [
    "### 불용어(nursing) 제거한 df를 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4250644",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"post-data/nursing_stopwords_removed.csv\", mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1616f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('post-data/nursing_stopwords_removed.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdac10c",
   "metadata": {},
   "source": [
    "## 동의어처리 (before spell check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db8a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_df = pd.read_csv('pre-data/synonym.csv')\n",
    "syn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e48d42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(syn_df['전문가 의미'])):\n",
    "    if syn_df['전문가 의미'][idx]==\"삭제\":\n",
    "        syn_df['synonym'][idx] = \"\" \n",
    "\n",
    "# synonym 행 중 값이 없는 행은 삭제\n",
    "syn_df = syn_df[syn_df['synonym'].notna()] \n",
    "syn_df = syn_df[['word', 'synonym']] \n",
    "\n",
    "# index 재구성\n",
    "len_syn = len(syn_df['synonym'])\n",
    "syn_index = [i for i in range(len_syn)]\n",
    "syn_df = syn_df.set_index(pd.Index(syn_index))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dde2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f93193",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_df = len(df)\n",
    "for i in range(len_df):\n",
    "    for j in range(len(syn_df['synonym'])):\n",
    "        df['title'][i] = re.sub(\" \"+syn_df.loc[j][\"word\"]+\" \", \" \"+syn_df.loc[j][\"synonym\"]+\" \", df['title'][i])\n",
    "    print(f\"{i} of {len_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14197ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00340b7d",
   "metadata": {},
   "source": [
    "### 동의어처리한 df 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492ce524",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"post-data/synyonym_checked_before_spell_chcking.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5315d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44dc2c33",
   "metadata": {},
   "source": [
    "## spell checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73274ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spell_list = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "# for i in range(10):\n",
    "    spell_list.append(spacing(df['title'][i]))\n",
    "    print(i, spell_list[i])\n",
    "\n",
    "df['spell'] = spell_list\n",
    "\n",
    "df.to_csv(\"post-data/spell_checked.csv\", mode='w')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97222db",
   "metadata": {},
   "source": [
    "## remove stopwords(korean) after spell checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c9199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kr_stopwords_df=stopwords_df.drop(['nursing'], axis=1).dropna()\n",
    "kr_stopwords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda76e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# korean\n",
    "len_df = len(df) \n",
    "for i in range(len_df):\n",
    "    for j in range(len(kr_stopwords_df['korean'])):\n",
    "        df['title'][i] = re.sub(\" \"+kr_stopwords_df.loc[j][\"korean\"]+\" \", \" \", df['title'][i])\n",
    "    print(f\"{i} of {len_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "338da095",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"post-data/korean_stopwords_removed.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e1f148",
   "metadata": {},
   "source": [
    "## 동의어처리 (after spell check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc67e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_df = len(df)\n",
    "for i in range(len_df):\n",
    "    for j in range(len(syn_df['synonym'])):\n",
    "        df['title'][i] = re.sub(\" \"+syn_df.loc[j][\"word\"]+\" \", \" \"+syn_df.loc[j][\"synonym\"]+\" \", df['title'][i])\n",
    "    print(f\"{i} of {len_df}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe4f78d",
   "metadata": {},
   "source": [
    "### 동의어처리한 df 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "948fbc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"post-data/synyonym_checked_after_spell_chcking.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d829a417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('post-data/synyonym_checked_after_spell_chcking.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db0c4e8",
   "metadata": {},
   "source": [
    "## tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083a856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d4729",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list=[]\n",
    "\n",
    "\n",
    "def title_tokenization(df, idx):\n",
    "    # return df['title'].replace([df['title'][idx]], \" \".join(\n",
    "    #     okt.nouns(df['title'][idx])))\n",
    "\n",
    "    return \" \".join(okt.nouns(df['spell'][idx]))\n",
    "\n",
    "for i in range(len(df)):\n",
    "    token_list.append(title_tokenization(df, i))\n",
    "    print(i, token_list[i])\n",
    "\n",
    "df['token'] = token_list\n",
    "\n",
    "df.to_csv(\"post-data/tokeniztioned.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9f60f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a1ab5d",
   "metadata": {},
   "source": [
    "## making matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f0e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = []\n",
    "index_list = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    index_list.append(i)\n",
    "    try:\n",
    "        token_list += df['token'][i].split()\n",
    "        print(f\"{i} of {len(df['token'])}\")\n",
    "    except AttributeError:  # token이 없는 경우 예외처리\n",
    "        print(f\"ERROR!\\n{i} : {df['token'][i]}\")\n",
    "\n",
    "print(f\"중복 제거 전 : {len(token_list)}개\")\n",
    "token_list = list(set(token_list))\n",
    "print(f\"중복 제거 후 : {len(token_list)}개\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47e355d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making matrix_df!\n",
      "nan to 0\n"
     ]
    }
   ],
   "source": [
    "print(\"making matrix_df!\")\n",
    "matrix_df = pd.DataFrame(index=index_list, columns=token_list)\n",
    "\n",
    "print(\"nan to 0\")\n",
    "matrix_df = matrix_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7657af7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aded625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in range(len(matrix_df.columns)):\n",
    "    print(f\"{col} of {len(matrix_df.columns)} : {matrix_df.columns[col]}\")\n",
    "    for idx in matrix_df.index:\n",
    "        try:\n",
    "            cnt = df['token'][idx].split().count(matrix_df.columns[col])\n",
    "            print(matrix_df[matrix_df.columns[col]][idx], cnt)\n",
    "            matrix_df[matrix_df.columns[col]][idx] = cnt\n",
    "            \n",
    "        except AttributeError:  # token이 없는 경우 예외처리\n",
    "            pass\n",
    "\n",
    "print(\"saving matrix_df!\")\n",
    "matrix_df.to_csv(\"post-data/matrix.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802b41e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_df = pd.read_csv('data/matrix.csv',low_memory=False)\n",
    "matrix_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac64aea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_df = matrix_df.transpose()\n",
    "matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e390fa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_df['freq'] = matrix_df.sum(axis=1)\n",
    "matrix_df = matrix_df[['freq']]\n",
    "matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791fe52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df = matrix_df.sort_values('freq' ,ascending=False)\n",
    "freq_df\n",
    "\n",
    "print(\"saving freq_df!\")\n",
    "matrix_df.to_csv(\"post-data/freq.csv\", mode='w', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4feb47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22735869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
